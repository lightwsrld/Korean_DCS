import json

import torch
from torch.utils.data import Dataset


class CustomDataset(Dataset):
    def __init__(self, fnames, tokenizer):
        IGNORE_INDEX=-100
        self.inp = []
        self.label = []

        data = None
        for fname in fnames:
            if not data:
                with open(fname, "r") as f:
                    data = json.load(f)
            else:
                with open(fname, "r") as f:
                    data += json.load(f)

        def make_chat(inp):
            chat = ["[Conversation]"]
            for cvt in inp['conversation']:
                speaker = cvt['speaker']
                utterance = cvt['utterance']
                chat.append(f"화자{speaker}: {utterance}")
            chat = "\n".join(chat)

            question = f"[Question]\n위 {', '.join(inp['subject_keyword'])} 주제에 대한 대화를 3문장 이내로 자세히 요약해주세요. \n [Output Format] \n [화자]은 [화자의 요점]이라고 말했습니다. [추가 설명] 또한 [관련 발언 요약]라고 말했습니다. \n [Caution] \n  주어진 대화에서 화자가 이야기한 모든 내용이 꼭 들어가야합니다."
            chat = chat + "\n\n" + question

            return chat
        
        for example in data:
            PROMPT = f'''
당신은 유능한 AI 어시스턴트 입니다. 사용자의 질문에 대해 친절하게 답변해주세요.
주어진 대화 내용을 바탕으로 [Task]를 수행하세요.

[예시1]
[Conversation]
화자SD2000001: 저는 여행 다니는 것을 굉장히 좋아하는데요. 그래가지고 스페인이나 뭐 영국 유럽 아니면 국내에서도 뭐 강릉이나 전주 같은 데를 많이 다녔는데
화자SD2000001: 혹시 여행 다니는 거 좋아하시나요?
화자SD2000001: 네. 저도 우연히 스페인과 포르투갈을 다녀왔었었습니다.
화자SD2000001: 저는 스페인 중에서도 마드리드에 근교에 있었던 톨레도라는 지역이 굉장히 좋았는데요. 그 톨레도에서 특히 기억에 남았던 거는 거기에 대성당이 있는데 그 성당이 엄청 화려하더라고요. 그래서 거기를 꾸며논 거를 보면은 금을 엄청 많이 사용해가지고 되게 빤짝빤짝하고 좀 성당은 보통 좀 소박하다라는 인식이 있었는데 아~ 이렇게 화려한 성당도 있구나라는 거를 새롭게 알게 됐었습니다.
화자SD2000001: 또 톨레도에 지역 음식도 같이 먹었었는데 아~ 이름은 지금 잘 생각이 나지 는 않지만 굉장히 달달했던 그런 디저트 종류였는데 그~ 디저트도 먹고 그다음에 천천히 걸어 다니면서 주변 풍경도 보고 근교 여행만의 약간 소박한 맛이 있었다고 생각을 합니다.
화자SD2000001: 또 물론 마드리드도 굉장히 좋았는데 유럽 여행을 많이 가셨다고 해서 혹시 톨레도도 가본 적이 있나요?
[Output Format] 
[화자]은 [화자의 요점]이라고 말했습니다. [추가 설명] 또한 [관련 발언 요약]라고 말했습니다.
[Subject keyword]
해외여행
[Task] 
대화의 내용을 subject_keyword를 중점으로 요약하여 3문장 이내로 "자세히" 요약하세요. 단, 주어진 대화에서 화자가 이야기한 모든 내용이 꼭 들어가야합니다.
[Output]
SD2000001은 여행을 좋아하여 국내, 해외 여행을 많이 다녔다고 말했습니다. 특히 기억에 남는 여행지로 스페인 마드리드의 톨레도를 소개했습니다. 그 중 화려하게 꾸며진 대성당과 디저트가 인상적이었다고 이야기했습니다.

[예시2]
[Conversation]
화자SD2000005: 저는 현재 다이어트를 하진 않지만 주위에서 들어보면은 보통 막 삶은 계란이나 뭐 샐러드 그리고 닭가슴살 같은 종류로 되게 칼로리 낮게 하고 영양가 되게 높게 해가지고 대개 그렇게 주로 드시더라고요. 주위에서 그래서 저는 만약에 다이어트를 한 다이어트 식품을 추천 을 한다면 샐러든데 샐러드도 종류가 많으니까 그중에서도 닭가슴살 샐러드 단호박 샐러드 종류 가 되게 다양하니까
화자SD2000005: 자기가 좋아하는 취향대로 굳이 되게 굳이 먹고 싶은 걸 어~ 되게 힘들게 참아가면서 하지 않아도 괜찮을 정도로 영양가 잘 챙겨서 먹으면은 되게 좋을 것 같아서 샐러드를 추천합니다.
화자SD2000005: 저는 마실 걸로는 어~ 우유가 들어간 걸 굉장히 선호합니다.
화자SD2000005: 되게 무슨 커피를 마실 때도 라떼로 마시면 좀 더 달기도 하고 아~ 제가 단 거를 좋아해서 되게 당도가 높은 음식을 선호하는데
화자SD2000005: 어~ 라떼나 아니면 그냥 밀크티나 아니면은 초코우유 딸기우유 이렇게 된 걸 좋 아하고 아니면은 우유는 들어 가지 않았지만 막 스무디도 좋아하고 막 파르페류도 되게 추 선호 합니다.
화자SD2000005: 되게 요즘 보면은 막 메가 커피 빽다방 이런 데서 되게 모양도 예쁘게 잘 만들어서 파니까 주로 주위에서 쉽게 접할 수 있고 해서 되게 자주 좋아하고 더 선호하고 되게 자주 이용하는 것 같아요.
화자SD2000005: 그리고 되게 주위에서 흔하게 볼 수 있으니까 더 익숙하기도 하고 어렸을 때부터 우유는 강제로 먹었 강제로든 어떻게든 먹긴 했으니까 좀 더 익숙하고 좋은 것 같습니다.
[Output Format] 
[화자]은 [화자의 요점]이라고 말했습니다. [추가 설명] 또한 [관련 발언 요약]라고 말했습니다.
[Subject keyword]
다이어트 식품, 마실것
[Task] 
대화의 내용을 subject_keyword를 중점으로 요약하여 3문장 이내로 "자세히" 요약하세요. 단, 주어진 대화에서 화자가 이야기한 모든 내용이 꼭 들어가야합니다.
[Answer]
두 화자는 이 대화에서 다이어트 식품과 좋아하는 음료에 대해 이야기했습니다. SD2000005는 다이어트 식품으로 영양가가 좋은 샐러드를 추천했고, 좋아하는 음료수로는 우유가 들어간 것을 이야기했습니다. 그 중 스무디와 파르페 종류도 좋아한다고 말했습니다.

'''
            chat = make_chat(example["input"])
            message = [
                {"role": "system", "content": PROMPT},
                {"role": "user", "content": chat},
            ]
     
            source = tokenizer.apply_chat_template(
                message,
                add_generation_prompt=True,
                return_tensors="pt",
            )

            target_text = example["output"]  # target 변수명을 target_text로 변경
            target = example["output"]
            if target != "":
                target += tokenizer.eos_token
            target = tokenizer(target,
                      return_attention_mask=False,
                      add_special_tokens=False,
                      return_tensors="pt")
            target["input_ids"] = target["input_ids"].type(torch.int64)

            input_ids = torch.concat((source[0], target["input_ids"][0]))
            labels = torch.concat((torch.LongTensor([IGNORE_INDEX] * source[0].shape[0]), target["input_ids"][0]))
            self.inp.append(input_ids)
            self.label.append(labels)

    def __len__(self):
        return len(self.inp)

    def __getitem__(self, idx):
        return self.inp[idx]


class DataCollatorForSupervisedDataset(object):
    def __init__(self, tokenizer):
        self.tokenizer = tokenizer

    def __call__(self, instances):
        input_ids, labels = tuple([instance[key] for instance in instances] for key in ("input_ids", "labels"))
        input_ids = torch.nn.utils.rnn.pad_sequence(
            [torch.tensor(ids) for ids in input_ids], batch_first=True, padding_value=self.tokenizer.pad_token_id
        )
        labels = torch.nn.utils.rnn.pad_sequence([torch.tensor(lbls) for lbls in labels], batch_first=True, padding_value=-100)
        return dict(
            input_ids=input_ids,
            labels=labels,
            attention_mask=input_ids.ne(self.tokenizer.pad_token_id),
        )
